{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "import sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nfrom awsglue.dynamicframe import DynamicFrame\nfrom pyspark.sql import functions as SqlFuncs\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.functions import col\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import current_date\n\n\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.38.1 \nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::940173853583:role/AWSGluestudio-datalake\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: 1cf47394-31d5-4d06-86ce-9caa465c9c16\nJob Type: glueetl\nApplying the following default arguments:\n--glue_kernel_version 0.38.1\n--enable-glue-datacatalog true\nWaiting for session 1cf47394-31d5-4d06-86ce-9caa465c9c16 to get into ready status...\nSession 1cf47394-31d5-4d06-86ce-9caa465c9c16 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "liq= (\n    glueContext.create_dynamic_frame.from_catalog(\n        database=\"gg-data-elhoy\",\n        table_name=\"liquidacion\",\n        transformation_ctx=\"liq\",\n    )\n)\n\nnota= (\n    glueContext.create_dynamic_frame.from_catalog(\n        database=\"gg-data-elhoy\",\n        table_name=\"nota\",\n        transformation_ctx=\"nota\",\n    )\n)\n\ndt= (\n    glueContext.create_dynamic_frame.from_catalog(\n        database=\"gg-data-elhoy\",\n        table_name=\"detalle_nota\",\n        transformation_ctx=\"dt\",\n    )\n)\n\n\n\ngn3api = (\n    glueContext.create_dynamic_frame.from_catalog(\n        database=\"gg_datalake_db_prod\",\n        table_name=\"globalnet_gn3_api_3\",\n        transformation_ctx=\"gn3api\",\n    )\n)\n\n\n\nu = (\n    glueContext.create_dynamic_frame.from_catalog(\n        database=\"gg_datalake_db_prod\",\n        table_name=\"globalnet_unidad\",\n        transformation_ctx=\"u\",\n    )\n)\n\ndire = glueContext.create_dynamic_frame.from_options(\n    format_options={\"quoteChar\": '\"', \"withHeader\": True, \"separator\": \",\"},\n    connection_type=\"s3\",\n    format=\"csv\",\n    connection_options={\n        \"paths\": [\n            \"s3://globalgas-datalake/datasets/raw/raw/direccion/Direcciones.csv\"\n        ],\n        \"recurse\": True,\n    },\n    transformation_ctx=\"dire\",\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "inv= (\n    glueContext.create_dynamic_frame.from_catalog(\n        database=\"gg-data-elhoy\",\n        table_name=\"inventario_gas\",\n        transformation_ctx=\"inv\",\n    )\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "obj_ef = glueContext.create_dynamic_frame.from_options(\n    format_options={\"quoteChar\": '\"', \"withHeader\": True, \"separator\": \",\"},\n    connection_type=\"s3\",\n    format=\"csv\",\n    connection_options={\n        \"paths\": [\n            \"s3://globalgas-datalake/cleaning_stepts/2022_2023/Presupuesto_eficiencia/Eficiencia_22_23.csv\"\n        ],\n        \"recurse\": True,\n    },\n    transformation_ctx=\"obj_ef\",\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def generate_series(start, stop, interval):\n    \"\"\"\n    :param start  - lower bound, inclusive\n    :param stop   - upper bound, exclusive\n    :interval int - increment interval in seconds\n    \"\"\"\n    spark = SparkSession.builder.getOrCreate()\n    # Determine start and stops in epoch seconds\n    start, stop = spark.createDataFrame(\n        [(start, stop)], (\"start\", \"stop\")\n    ).select(\n        [col(c).cast(\"timestamp\").cast(\"long\") for c in (\"start\", \"stop\")\n    ]).first()\n    # Create range with increments and cast to timestamp\n    return spark.range(start, stop, interval).select(\n        col(\"id\").cast(\"timestamp\").alias(\"value\")\n    )",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "starting_date  = '2022-01-01'",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "liq00 = liq.toDF()\nn00 = nota.toDF()\nliq0 = liq00.filter(liq00.eliminado_logico == \"NO\")\nn0 = n00.filter(n00.eliminado_logico == \"NO\") \nd0 = dt.toDF()\nu0 = u.toDF()\ndire1 = dire.toDF().select('Direccion','Entidad_Legal', 'planta_datalake')\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "obef1 = obj_ef.toDF()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "api = gn3api.toDF()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "inv1 = inv.toDF()\ninv2 = inv1.filter(inv1.eliminado_logico == \"NO\").select('fecha_hora', 'planta', 'diferencia')\ninv3 =  inv2.withColumn('fecha1', to_date(col(\"fecha_hora\")) ).drop('fecha_hora').withColumn('planta_datalake1', concat(lit('Planta'),inv2.planta )).drop('planta')\ninv3 = inv3.filter(inv3.fecha1 >= starting_date)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "inv3 = inv3.groupBy('planta_datalake1', 'fecha1').sum('diferencia').withColumnRenamed('sum(diferencia)', 'diferencia')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "api1 = api.withColumn('date1', to_date(col(\"date\")))\napi2 = api1.groupBy('planta_datalake', 'date1').pivot(\"unitType\").sum('totalQuantity').withColumnRenamed('sum(totalQuantity)', 'totalquantity').withColumnRenamed('date1', 'date')\napi2 = api2.withColumnRenamed(\"PORTATIL\", \"PORTATIL_e\").withColumnRenamed(\"ESTACION\", \"ESTACION_e\").withColumnRenamed(\"ESTACIONARIO\", \"ESTACIONARIO_e\").withColumnRenamed(\"MAYORISTA_E\", \"MAYORISTA_E_e\").withColumnRenamed(\"ANDEN\", \"ANDEN_e\").withColumnRenamed(\"MAYORISTA_P\", \"MAYORISTA_P_e\").fillna(0)\napi2 = api2.withColumn('totalquantity',  api2.ANDEN_e +api2.ESTACION_e+api2.ESTACIONARIO_e + api2.MAYORISTA_E_e + api2.MAYORISTA_P_e+ api2.PORTATIL_e)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 13,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "api2.columns",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 14,
			"outputs": [
				{
					"name": "stdout",
					"text": "['planta_datalake', 'date', 'ANDEN_e', 'ESTACION_e', 'ESTACIONARIO_e', 'MAYORISTA_E_e', 'MAYORISTA_P_e', 'PORTATIL_e', 'totalquantity']\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "n1 = n0.withColumnRenamed('id_planta', 'id_planta1').withColumnRenamed('id_liquidacion', 'id_liquidacion1').withColumnRenamed('planta', 'planta1')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 15,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#join liq-nota\nln = liq0.join(n1, (liq0.id_liquidacion == n1.id_liquidacion1) & (liq0.id_planta == n1.id_planta1), \"fullouter\" )\nln1 = ln.select(\"id_planta\", \"id_liquidacion\", \"fecha_liquidacion\",\"id_nota\", \"id_unidad\", 'planta')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 16,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "d1 = d0.withColumnRenamed('id_planta', 'id_planta1').withColumnRenamed('id_nota', 'id_nota1').withColumnRenamed('planta', 'planta1')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 17,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "##join liq-nota-detallenota\nld = ln1.join(d1, (ln1.id_nota == d1.id_nota1) & (ln1.id_planta == d1.id_planta1), \"fullouter\" )\nld1 = ld.select(\"id_planta\",'planta', \"id_liquidacion\", \"fecha_liquidacion\",\"id_nota\", \"id_unidad\", \"kilos\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "u1 = u0.withColumnRenamed('id_unidad', 'id_unidad1').withColumnRenamed('id_planta', 'id_planta1').withColumnRenamed('planta', 'planta1')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 19,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "##Join liq-nota-detallenota-unidad\nlu = ld1.join(u1, (ld1.id_unidad == u1.id_unidad1) & (ld1.id_planta == u1.id_planta1), \"fullouter\")\nlu1 = lu.select(\"id_planta\", \"id_liquidacion\", 'planta',\"fecha_liquidacion\",\"id_nota\", \"id_unidad\", \"kilos\", \"tipo_unidad\")\n### agrupacion lu",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 20,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "lu2 = lu1.fillna(0)\nlu3 = lu1.groupBy(\"id_planta\",'planta', \"id_liquidacion\", \"fecha_liquidacion\", \"id_unidad\",\"tipo_unidad\").sum(\"kilos\").withColumnRenamed(\"sum(kilos)\", \"kilos\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "lu4 = lu3.withColumn(\"fecha_liquidacion_day\",to_date(col(\"fecha_liquidacion\")))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 22,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "lu5 = lu4.groupBy('fecha_liquidacion_day',  'planta').sum('kilos')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 23,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "lu6 = lu5.withColumn('planta_datalake', concat(lit('Planta'), lu5.planta )  ).withColumnRenamed('sum(kilos)', 'kilos' ).drop('planta')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 24,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Generar la serie de tiempo para todos los registros",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df = generate_series(\"2022-01-01\", \"2023-04-17\", 60 * 60 * 24)\ndf1 = df.withColumn(\"current_date\",current_date())\nl1 = df1.select(\"current_date\").collect()\ndf2 = generate_series(\"2017-01-01\", l1[0].current_date, 60 * 60 * 24)\ndf3 = df2.withColumn(\"fecha\", to_date(col(\"value\")))\ndf4 = df3.drop(\"value\")\nliq3 = liq.toDF()\na = liq3.select(\"planta\").distinct().orderBy(\"planta\").collect()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 25,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df5 = df4.withColumn(\"planta\", lit(a[1].planta))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 26,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df5 = df4.withColumn(\"planta\", lit(a[0].planta))\nfor i in range(len(a)):\n    df6 = df4.withColumn(\"planta\", lit(a[i].planta))\n    df5 = df5.union(df6)\n\ndf7 =  df5.distinct()\ndf8 = df7.withColumnRenamed(\"planta\",\"planta1\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 27,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df9 = df8.withColumn('planta_datalake1', concat(lit('Planta'), df8.planta1 )  )",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 28,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df10 = df9.filter(df9.planta1.isNotNull())\ndf11 = df10.join(lu6, ((df10.planta_datalake1 ==  lu6.planta_datalake) & (df10.fecha == lu6.fecha_liquidacion_day)), \"fullouter\")\ndf11 = df11.select(coalesce(\"planta_datalake1\", \"planta_datalake\"),  coalesce(\"fecha_liquidacion_day\", \"fecha\"), 'kilos').withColumnRenamed('coalesce(planta_datalake1, planta_datalake)', 'planta_datalake1').withColumnRenamed('coalesce(fecha_liquidacion_day, fecha)', 'fecha' )\n#lu6.columns",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 29,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df12 = df11.join(api2, ((df11.planta_datalake1 ==  api2.planta_datalake) & (df11.fecha == api2.date)), \"fullouter\")\ndf12 = df12.select(coalesce('planta_datalake1','planta_datalake'), coalesce('fecha','date'), 'kilos', 'totalQuantity','ANDEN_e', 'ESTACION_e', 'ESTACIONARIO_e', 'MAYORISTA_E_e', 'MAYORISTA_P_e', 'PORTATIL_e',).withColumnRenamed('coalesce(planta_datalake1, planta_datalake)', 'planta_datalake1').withColumnRenamed('coalesce(fecha, date)', 'date')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 30,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df14 = df12.filter(df12.planta_datalake1.isNotNull()).filter(df12.date >= starting_date)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 31,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df15 = df14.join(dire1, ((df14.planta_datalake1 ==  dire1.planta_datalake)), \"fullouter\")\ndf15 = df15.select('date', 'kilos', 'totalQuantity', 'ANDEN_e', 'ESTACION_e', 'ESTACIONARIO_e', 'MAYORISTA_E_e', 'MAYORISTA_P_e', 'PORTATIL_e','Direccion', 'Entidad_Legal', coalesce('planta_datalake1','planta_datalake')).withColumnRenamed('coalesce(planta_datalake1, planta_datalake)', 'planta_datalake')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 37,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df16 = df15.join(inv3, (df15.planta_datalake == inv3.planta_datalake1) & (df15.date == inv3.fecha1), 'outer')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 38,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Select features",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df17 = df16.select(coalesce(\"date\", \"fecha1\"), 'kilos', 'ANDEN_e', 'ESTACION_e', 'ESTACIONARIO_e', 'MAYORISTA_E_e', 'MAYORISTA_P_e', 'PORTATIL_e','totalQuantity', 'Direccion', 'Entidad_Legal', coalesce('planta_datalake1','planta_datalake')).withColumnRenamed('coalesce(planta_datalake1, planta_datalake)', 'planta_datalake').withColumnRenamed('coalesce(date, fecha1)', 'fecha')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 39,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df18 = df17.filter(df17.planta_datalake.isNotNull()).filter(df17.fecha >= starting_date)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 40,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df19 = df18.join(inv3, ((df18.planta_datalake == inv3.planta_datalake1) & (df18.fecha == inv3.fecha1) ), 'outer')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 41,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df20 = df19.select('kilos','ANDEN_e', 'ESTACION_e', 'ESTACIONARIO_e', 'MAYORISTA_E_e', 'MAYORISTA_P_e', 'PORTATIL_e', 'totalQuantity', 'Direccion', 'Entidad_Legal','diferencia',coalesce(\"fecha\", \"fecha1\"), coalesce('planta_datalake1', 'planta_datalake')).withColumnRenamed('coalesce(planta_datalake1, planta_datalake)', 'planta_datalake1').withColumnRenamed('coalesce(fecha, fecha1)', 'fecha')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 46,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Add year_month",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "lc8 = df20.withColumn(\"Mes\", df20.fecha.cast(\"string\").substr(6,2))\nlc99 = lc8.withColumn(\"Year\", lc8.fecha.cast(\"string\").substr(3,2))\nlc9 = lc99.filter(lc99.Year.cast(\"int\")> 21)\n#lc10 = lc9.withColumn(\"Month\", monthUDF(col(\"Mes\")))\nlc10 = lc9.withColumn(\"Month\", when(lc9.Mes == \"01\", \"Jan\").otherwise(when(lc9.Mes == \"02\", \"Feb\").otherwise(when(lc9.Mes == \"03\", \"Mar\").otherwise(when(lc9.Mes == \"04\", \"Apr\").otherwise(when(lc9.Mes == \"05\", \"May\").otherwise(when(lc9.Mes == \"06\", \"Jun\").otherwise(when(lc9.Mes == \"07\", \"Jul\").otherwise(when(lc9.Mes == \"08\", \"Aug\").otherwise(when(lc9.Mes == \"09\", \"Sep\").otherwise(when(lc9.Mes == \"10\", \"Oct\").otherwise(when(lc9.Mes == \"11\", \"Nov\").otherwise(when(lc9.Mes == \"12\", \"Dic\").otherwise(\"0\")))))))))))))\nlc11= lc10.withColumn(\"year-month\", concat(lc10.Month, lit(\"-\"), lc10.Year))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 47,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df21 = lc11.filter(lc11.fecha >= starting_date).filter(lc11.planta_datalake1.isNotNull()).drop('Mes', 'Year', 'Month')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 48,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Obj eficiencia",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "unpivot_ef = \"stack(12, 'Jan', Enero, 'Feb', Febrero, 'Mar', Marzo, 'Apr', Abril, 'May', Mayo, 'Jun', Junio, 'Jul', Julio, 'Aug', Agosto, 'Sep', Septiembre, 'Oct', Octubre, 'Nov', Noviembre, 'Dec', Diciembre) as (Mes,proyeccion_ef)\"\nobef22 = obef1.select(\"planta_datalake\",'Year' ,expr(unpivot_ef))\nobef33 =  obef22.withColumn(\"month_year2\", concat(obef22.Mes, lit('-'),obef22.Year.cast(\"string\").substr(3,2)))\n#obef3 = obef33.withColumn(\"proy_ef\", when(length(obef33.proyeccion_ef.cast(\"string\"))==  5, obef33.proyeccion_ef.cast(\"string\").substr(1,8).cast(\"double\")).otherwise(obef33.proyeccion_ef.cast(\"string\").substr(1,5).cast(\"double\"))).drop(\"proyeccion_ef\").withColumnRenamed(\"proy_ef\",\"proyeccion_ef\").drop('Year')\nobef3 = obef33.withColumn(\"proy_ef\", obef33.proyeccion_ef.cast(\"string\").substr(1,8).cast(\"double\")).drop(\"proyeccion_ef\").withColumnRenamed(\"proy_ef\",\"proyeccion_ef\").drop('Year')\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 49,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df22 = df21.join(obef3, ((df21.planta_datalake1 ==  obef3.planta_datalake) & (df21['year-month'] == obef3.month_year2)), \"left\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 50,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df23 =df22.select('kilos', 'ANDEN_e', 'ESTACION_e', 'ESTACIONARIO_e', 'MAYORISTA_E_e', 'MAYORISTA_P_e', 'PORTATIL_e','totalQuantity', 'Direccion', 'Entidad_Legal','diferencia','proyeccion_ef', 'fecha',coalesce(\"year-month\", \"month_year2\"), coalesce('planta_datalake1', 'planta_datalake')).withColumnRenamed('coalesce(planta_datalake1, planta_datalake)', 'planta_datalake').withColumnRenamed('coalesce(year-month, month_year2)', 'year-month')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 51,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df23.columns",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 52,
			"outputs": [
				{
					"name": "stdout",
					"text": "['kilos', 'ANDEN_e', 'ESTACION_e', 'ESTACIONARIO_e', 'MAYORISTA_E_e', 'MAYORISTA_P_e', 'PORTATIL_e', 'totalQuantity', 'Direccion', 'Entidad_Legal', 'diferencia', 'proyeccion_ef', 'fecha', 'year-month', 'planta_datalake']\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df23.write.mode(\"overwrite\").format(\"parquet\").save(\"s3://globalgas-datalake/datasets/raw/raw/eficiencia_diaria/\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 53,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}